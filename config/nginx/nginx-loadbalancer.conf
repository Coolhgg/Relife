# Nginx Load Balancer Configuration for Relife Smart Alarm App
# High availability setup with multiple backend servers

user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

# Load balancing modules
load_module modules/ngx_http_upstream_module.so;
load_module modules/ngx_stream_module.so;

events {
    worker_connections 2048;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    
    # Logging for load balancer
    log_format loadbalancer '$remote_addr - $remote_user [$time_local] '
                           '"$request" $status $body_bytes_sent '
                           '"$http_referer" "$http_user_agent" '
                           'upstream_addr=$upstream_addr '
                           'upstream_status=$upstream_status '
                           'upstream_response_time=$upstream_response_time '
                           'upstream_connect_time=$upstream_connect_time '
                           'upstream_header_time=$upstream_header_time '
                           'request_time=$request_time';
    
    access_log /var/log/nginx/access.log loadbalancer;
    
    # Basic settings
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    server_tokens off;
    
    # Gzip
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml text/javascript application/javascript application/json application/xml+rss;
    
    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=100r/s;
    limit_req_zone $binary_remote_addr zone=static:10m rate=200r/s;
    
    # Connection limiting
    limit_conn_zone $binary_remote_addr zone=conn_limit:10m;
    
    # Upstream configuration for App servers
    upstream app_backend {
        # Load balancing method
        least_conn;
        
        # App servers
        server app1:80 max_fails=3 fail_timeout=30s weight=3;
        server app2:80 max_fails=3 fail_timeout=30s weight=3;
        server app3:80 max_fails=3 fail_timeout=30s weight=2 backup;
        
        # Health check
        # server app-healthcheck:80 max_fails=1 fail_timeout=10s down;
        
        # Keep-alive connections
        keepalive 32;
        keepalive_requests 100;
        keepalive_timeout 60s;
    }
    
    # Upstream configuration for API servers
    upstream api_backend {
        # Consistent hashing for session affinity
        ip_hash;
        
        # API servers
        server api1:3001 max_fails=2 fail_timeout=20s weight=3;
        server api2:3001 max_fails=2 fail_timeout=20s weight=3;
        server api3:3001 max_fails=2 fail_timeout=20s weight=2 backup;
        
        # Keep-alive connections
        keepalive 64;
        keepalive_requests 200;
        keepalive_timeout 60s;
    }
    
    # Upstream for performance monitoring
    upstream monitoring_backend {
        least_conn;
        
        server monitoring1:3002 max_fails=2 fail_timeout=30s;
        server monitoring2:3002 max_fails=2 fail_timeout=30s;
        
        keepalive 16;
    }
    
    # Cache configuration
    proxy_cache_path /var/cache/nginx/app_cache 
                     levels=1:2 
                     keys_zone=app_cache:50m 
                     max_size=1g 
                     inactive=1h;
    
    proxy_cache_path /var/cache/nginx/api_cache 
                     levels=1:2 
                     keys_zone=api_cache:50m 
                     max_size=500m 
                     inactive=30m;
    
    # Main load balancer server
    server {
        listen 80;
        server_name relife.app www.relife.app;
        
        # Connection limits
        limit_conn conn_limit 100;
        
        # Health check endpoint for load balancer
        location /lb_health {
            access_log off;
            return 200 '{"status":"healthy","upstream_servers":{"app":"$upstream_addr","api":"available"},"timestamp":"$time_iso8601"}';
            add_header Content-Type application/json;
        }
        
        # API endpoints - route to API backend
        location /api/ {
            limit_req zone=api burst=200 nodelay;
            
            # Proxy to API backend
            proxy_pass http://api_backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            
            # Load balancer headers
            add_header X-Upstream-Server $upstream_addr always;
            add_header X-Load-Balancer "nginx" always;
            
            # Caching for specific API endpoints
            proxy_cache api_cache;
            proxy_cache_valid 200 5m;
            proxy_cache_valid 404 1m;
            proxy_cache_key "$scheme$request_method$host$request_uri$is_args$args";
            proxy_cache_bypass $cookie_nocache $arg_nocache;
            
            # Health check and failover
            proxy_next_upstream error timeout http_500 http_502 http_503 http_504;
            proxy_next_upstream_tries 3;
            proxy_next_upstream_timeout 10s;
            
            # Timeouts
            proxy_connect_timeout 5s;
            proxy_send_timeout 10s;
            proxy_read_timeout 10s;
            
            # Buffer configuration
            proxy_buffering on;
            proxy_buffer_size 16k;
            proxy_buffers 8 16k;
            proxy_busy_buffers_size 32k;
        }
        
        # Performance monitoring endpoint
        location /monitoring/ {
            proxy_pass http://monitoring_backend/;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # No caching for monitoring
            proxy_no_cache 1;
            proxy_cache_bypass 1;
            
            # Timeouts
            proxy_connect_timeout 3s;
            proxy_send_timeout 5s;
            proxy_read_timeout 5s;
        }
        
        # Static files - serve directly or proxy to app backend
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot|webp|avif)$ {
            limit_req zone=static burst=300 nodelay;
            
            # Try local files first, then proxy to backend
            try_files $uri @proxy_static;
            
            # Caching headers
            expires 1y;
            add_header Cache-Control "public, immutable";
            add_header Vary "Accept-Encoding";
            
            # Security headers
            add_header X-Content-Type-Options "nosniff";
            
            access_log off;
        }
        
        # Proxy static files to backend if not found locally
        location @proxy_static {
            proxy_pass http://app_backend;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Aggressive caching for static files
            proxy_cache app_cache;
            proxy_cache_valid 200 1d;
            proxy_cache_key "$scheme$request_method$host$request_uri";
            add_header X-Cache-Status $upstream_cache_status;
            
            # Caching headers
            expires 1y;
            add_header Cache-Control "public, immutable";
            
            access_log off;
        }
        
        # All other requests - proxy to app backend
        location / {
            limit_req zone=static burst=100 nodelay;
            
            # Proxy to app backend
            proxy_pass http://app_backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            
            # Load balancer headers
            add_header X-Upstream-Server $upstream_addr always;
            add_header X-Load-Balancer "nginx" always;
            
            # Failover configuration
            proxy_next_upstream error timeout http_500 http_502 http_503 http_504;
            proxy_next_upstream_tries 2;
            proxy_next_upstream_timeout 5s;
            
            # Timeouts
            proxy_connect_timeout 3s;
            proxy_send_timeout 10s;
            proxy_read_timeout 10s;
            
            # Buffer configuration
            proxy_buffering on;
            proxy_buffer_size 8k;
            proxy_buffers 16 8k;
            proxy_busy_buffers_size 16k;
            
            # Security headers
            add_header X-Frame-Options "SAMEORIGIN" always;
            add_header X-XSS-Protection "1; mode=block" always;
            add_header X-Content-Type-Options "nosniff" always;
        }
        
        # Error pages
        error_page 500 502 503 504 /50x.html;
        location = /50x.html {
            root /usr/share/nginx/html;
        }
    }
    
    # Upstream status server (for monitoring)
    server {
        listen 8080;
        server_name localhost;
        
        # Upstream status endpoint
        location /upstream_status {
            # Include status information about upstreams
            access_log off;
            
            # Return upstream server status
            return 200 '{"app_backend":{"servers":3,"healthy":2},"api_backend":{"servers":3,"healthy":3},"monitoring_backend":{"servers":2,"healthy":2},"timestamp":"$time_iso8601"}';
            add_header Content-Type application/json;
        }
        
        # Nginx status
        location /nginx_status {
            stub_status on;
            access_log off;
            allow 127.0.0.1;
            allow 10.0.0.0/8;
            allow 172.16.0.0/12;
            allow 192.168.0.0/16;
            deny all;
        }
    }
}

# Stream module for TCP/UDP load balancing
stream {
    # Logging for stream
    log_format stream '$remote_addr [$time_local] $protocol $status $bytes_sent $bytes_received $session_time upstream_addr="$upstream_addr" upstream_bytes_sent="$upstream_bytes_sent" upstream_bytes_received="$upstream_bytes_received" upstream_connect_time="$upstream_connect_time"';
    
    access_log /var/log/nginx/stream.log stream;
    
    # Upstream for database connections (if needed)
    upstream database_backend {
        least_conn;
        server db1:5432 max_fails=3 fail_timeout=30s;
        server db2:5432 max_fails=3 fail_timeout=30s;
    }
    
    # Database load balancing
    server {
        listen 5432;
        proxy_pass database_backend;
        proxy_timeout 1s;
        proxy_responses 1;
        proxy_connect_timeout 1s;
    }
    
    # Redis load balancing
    upstream redis_backend {
        server redis1:6379 max_fails=2 fail_timeout=20s;
        server redis2:6379 max_fails=2 fail_timeout=20s backup;
    }
    
    server {
        listen 6379;
        proxy_pass redis_backend;
        proxy_timeout 3s;
        proxy_responses 1;
        proxy_connect_timeout 1s;
    }
}