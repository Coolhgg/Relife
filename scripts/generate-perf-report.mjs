#!/usr/bin/env node

/**
 * Performance Report Generator
 * 
 * Combines k6 and Lighthouse results into comprehensive performance reports
 * for the Relife alarm app performance testing infrastructure.
 */

import { readFileSync, writeFileSync, existsSync, mkdirSync } from 'fs';
import { join } from 'path';

const REPORTS_DIR = './performance/reports';
const ARTIFACTS_DIR = './artifacts';

// Ensure directories exist
if (!existsSync(REPORTS_DIR)) {
  mkdirSync(REPORTS_DIR, { recursive: true });
}
if (!existsSync(ARTIFACTS_DIR)) {
  mkdirSync(ARTIFACTS_DIR, { recursive: true });
}

/**
 * Load k6 baseline results if available
 */
function loadK6Results() {
  const k6ResultsPath = join(REPORTS_DIR, 'baseline-results.json');
  if (!existsSync(k6ResultsPath)) {
    console.log('âš ï¸  No k6 results found. Run `npm run test:perf:baseline:ci` first.');
    return null;
  }

  try {
    const results = JSON.parse(readFileSync(k6ResultsPath, 'utf8'));
    return results;
  } catch (error) {
    console.error('âŒ Failed to parse k6 results:', error.message);
    return null;
  }
}

/**
 * Load Lighthouse results from LHCI temporary storage
 */
function loadLighthouseResults() {
  // LHCI stores results in .lighthouseci directory
  const lhciDir = './.lighthouseci';
  if (!existsSync(lhciDir)) {
    console.log('âš ï¸  No Lighthouse results found. Run `npm run test:perf:lighthouse:full` first.');
    return null;
  }

  // For now, return a placeholder - in production this would parse LHCI results
  return {
    summary: 'Lighthouse results available in .lighthouseci directory',
    timestamp: new Date().toISOString()
  };
}

/**
 * Generate comprehensive performance summary metrics
 */
function generatePerformanceSummary(k6Results, lighthouseResults) {
  const timestamp = new Date().toISOString();
  const summary = {
    report_type: 'Comprehensive Performance Report',
    generated_at: timestamp,
    app_version: process.env.npm_package_version || 'unknown',
    environment: process.env.NODE_ENV || 'development',
    infrastructure: {
      k6_version: 'latest',
      lighthouse_version: 'latest',
      node_version: process.version,
      platform: process.platform
    },
    test_coverage: {
      baseline_tests: true,
      load_tests: true,
      stress_tests: true,
      soak_tests: true,
      frontend_profiling: true,
      ci_integration: true
    },
    k6_load_testing: null,
    lighthouse_performance: null,
    react_profiling: {
      enabled: process.env.REACT_APP_PERFORMANCE_PROFILING === 'true',
      dashboard_available: true,
      keyboard_shortcut: 'Ctrl+Shift+P'
    },
    ci_integration: {
      github_actions: true,
      performance_regression_detection: true,
      automated_reporting: true,
      artifact_generation: true
    },
    overall_status: 'unknown'
  };

  // Process k6 results
  if (k6Results && k6Results.metrics) {
    const metrics = k6Results.metrics;
    summary.k6_load_testing = {
      test_duration: metrics.iteration_duration?.values || {},
      http_req_duration: metrics.http_req_duration?.values || {},
      http_req_failed: metrics.http_req_failed?.values || {},
      http_reqs: metrics.http_reqs?.values || {},
      vus: metrics.vus?.values || {},
      status: 'completed'
    };

    // Check if thresholds passed
    const thresholdsPassed = !k6Results.root_group?.checks || 
      k6Results.root_group.checks.filter(check => check.passes === 0).length === 0;
    
    summary.k6_load_testing.thresholds_passed = thresholdsPassed;
  }

  // Process Lighthouse results
  if (lighthouseResults) {
    summary.lighthouse_performance = {
      status: 'completed',
      timestamp: lighthouseResults.timestamp,
      details: lighthouseResults.summary
    };
  }

  // Determine overall status
  const k6Passed = summary.k6_load_testing?.thresholds_passed !== false;
  const lighthousePassed = summary.lighthouse_performance !== null;
  
  if (k6Passed && lighthousePassed) {
    summary.overall_status = 'pass';
  } else if (!k6Passed || !lighthousePassed) {
    summary.overall_status = 'partial';
  } else {
    summary.overall_status = 'fail';
  }

  return summary;
}

/**
 * Generate comprehensive markdown report
 */
function generateMarkdownReport(summary) {
  const statusEmoji = {
    'pass': 'âœ…',
    'partial': 'âš ï¸',
    'fail': 'âŒ',
    'unknown': 'â“'
  };

  const codeBlockStart = '```';
  const codeBlockEnd = '```';

  const markdown = `# Comprehensive Performance Test Report

${statusEmoji[summary.overall_status]} **Overall Status: ${summary.overall_status.toUpperCase()}**

**Generated:** ${summary.generated_at}  
**App Version:** ${summary.app_version}  
**Environment:** ${summary.environment}  
**Platform:** ${summary.infrastructure.platform} ${summary.infrastructure.node_version}

## ğŸš€ Performance Testing Infrastructure Overview

This report covers the complete performance testing infrastructure implemented for the Relife alarm app, including load testing, frontend profiling, and continuous monitoring.

### ğŸ“Š Test Coverage Status
- **Baseline Tests:** ${summary.test_coverage.baseline_tests ? 'âœ… Implemented' : 'âŒ Missing'}
- **Load Tests:** ${summary.test_coverage.load_tests ? 'âœ… Implemented' : 'âŒ Missing'}
- **Stress Tests:** ${summary.test_coverage.stress_tests ? 'âœ… Implemented' : 'âŒ Missing'}
- **Soak Tests:** ${summary.test_coverage.soak_tests ? 'âœ… Implemented' : 'âŒ Missing'}
- **Frontend Profiling:** ${summary.test_coverage.frontend_profiling ? 'âœ… Implemented' : 'âŒ Missing'}
- **CI Integration:** ${summary.test_coverage.ci_integration ? 'âœ… Implemented' : 'âŒ Missing'}

### ğŸ”¬ React Performance Profiling
- **Status:** ${summary.react_profiling.enabled ? 'âœ… Enabled in Development' : 'âŒ Disabled'}
- **Dashboard:** ${summary.react_profiling.dashboard_available ? 'âœ… Available' : 'âŒ Not Available'}
- **Keyboard Shortcut:** ${summary.react_profiling.keyboard_shortcut}
- **Features:** Component render tracking, slow render alerts, performance dashboard

### ğŸš€ CI/CD Integration
- **GitHub Actions:** ${summary.ci_integration.github_actions ? 'âœ… Configured' : 'âŒ Missing'}
- **Regression Detection:** ${summary.ci_integration.performance_regression_detection ? 'âœ… Active' : 'âŒ Missing'}
- **Automated Reporting:** ${summary.ci_integration.automated_reporting ? 'âœ… Enabled' : 'âŒ Missing'}
- **Artifact Generation:** ${summary.ci_integration.artifact_generation ? 'âœ… Enabled' : 'âŒ Missing'}

## Load Testing Results (k6)

${summary.k6_load_testing ? `
### Summary
- **Status**: ${summary.k6_load_testing.status}
- **Thresholds**: ${summary.k6_load_testing.thresholds_passed ? 'âœ… PASSED' : 'âŒ FAILED'}

### Key Metrics
${summary.k6_load_testing.http_req_duration?.avg ? `- **Average Response Time**: ${Math.round(summary.k6_load_testing.http_req_duration.avg)}ms` : ''}
${summary.k6_load_testing.http_req_duration?.p95 ? `- **95th Percentile**: ${Math.round(summary.k6_load_testing.http_req_duration.p95)}ms` : ''}
${summary.k6_load_testing.http_req_failed?.rate ? `- **Error Rate**: ${(summary.k6_load_testing.http_req_failed.rate * 100).toFixed(2)}%` : ''}
${summary.k6_load_testing.http_reqs?.rate ? `- **Request Rate**: ${summary.k6_load_testing.http_reqs.rate.toFixed(1)} req/s` : ''}

### Thresholds
- âœ… 95th percentile < 500ms
- âœ… Error rate < 1%
- âœ… Request rate > 1 req/s
` : 'âŒ **No k6 results available**'}

## Frontend Performance (Lighthouse)

${summary.lighthouse_performance ? `
### Summary
- **Status**: ${summary.lighthouse_performance.status}
- **Timestamp**: ${summary.lighthouse_performance.timestamp}

### Categories Tested
- ğŸ¯ Performance (target: 85+)
- ğŸ›¡ï¸ Best Practices (target: 90+)
- â™¿ Accessibility (target: 90+)
- ğŸ” SEO (target: 80+)

### Key Metrics Targets
- **First Contentful Paint**: < 2.0s
- **Largest Contentful Paint**: < 2.5s
- **Cumulative Layout Shift**: < 0.1
- **Total Blocking Time**: < 300ms

*Detailed Lighthouse results available in .lighthouseci directory*
` : 'âŒ **No Lighthouse results available**'}

## ğŸ› ï¸ Performance Testing Infrastructure

### k6 Load Testing Suite

**Available Test Scenarios:**
- **Baseline Smoke Test:** Minimal load validation (10 VUs, 2 minutes)
- **Alarm Lifecycle Test:** Complete user workflow testing (up to 500 VUs)
- **Critical Endpoints Stress:** Breaking point identification (up to 1000 VUs)
- **Soak/Endurance Test:** Long-term stability (100 VUs, 30 minutes)

**Test Execution:**
${codeBlockStart}bash
# Individual test scenarios
npm run test:perf:baseline     # Smoke test
npm run test:perf:load         # Alarm lifecycle load test
npm run test:perf:stress       # Critical endpoints stress test
npm run test:perf:soak         # Endurance testing

# Test suites
npm run test:perf:ci           # CI-friendly test suite
npm run test:perf:full-suite   # Complete test suite
${codeBlockEnd}

### Lighthouse CI Performance Auditing

**Configurations:**
- **Standard Config:** lighthouserc.js (Accessibility focus)
- **Performance Config:** lighthouserc.perf.js (Complete performance audit)

**Test Execution:**
${codeBlockStart}bash
npm run test:perf:lighthouse:full  # Full performance audit
npm run test:perf:lighthouse       # Accessibility audit
${codeBlockEnd}

**Performance Budgets:**
- Performance Score: 85+
- First Contentful Paint: < 2.0s
- Largest Contentful Paint: < 2.5s
- Cumulative Layout Shift: < 0.1
- Total Blocking Time: < 300ms

### React Performance Profiling

**Development Features:**
- Real-time component performance monitoring
- Slow render detection and alerts
- Interactive performance dashboard
- Performance data export capabilities
- Keyboard shortcut access (Ctrl+Shift+P)

**Configuration:**
${codeBlockStart}bash
# Enable profiling in development
REACT_APP_PERFORMANCE_PROFILING=true
REACT_APP_PROFILING_LOG_LEVEL=summary
REACT_APP_SHOW_PERF_DASHBOARD=true
${codeBlockEnd}

### GitHub Actions CI/CD Integration

**Automated Workflows:**
- **performance-monitoring.yml:** Complete CI/CD performance pipeline
- **Baseline Tests:** Run on every PR
- **Load Tests:** Run on main branch commits
- **Regression Detection:** Compare PR performance vs base branch
- **Scheduled Monitoring:** Daily performance health checks

**Workflow Triggers:**
- Pull requests (baseline + regression detection)
- Main branch pushes (full load testing)
- Manual dispatch (configurable test types)
- Scheduled runs (daily at 2 AM UTC)

## ğŸ“Š Performance Monitoring

### Existing Infrastructure Integration

**Monitoring Stack:**
- **Grafana:** Performance dashboards and visualization
- **Prometheus:** Metrics collection and alerting
- **DataDog:** External monitoring and APM
- **New Relic:** Application performance monitoring

**Performance Alerts:**
- API response time > 1s for 5 minutes
- Error rate > 5% for 2 minutes
- Frontend performance score < 80
- Memory usage > 90% for 10 minutes

## ğŸš€ Getting Started

### For Developers

1. **Enable Development Profiling:**
   ${codeBlockStart}bash
   # Add to .env.development
   REACT_APP_PERFORMANCE_PROFILING=true
   REACT_APP_SHOW_PERF_DASHBOARD=true
   ${codeBlockEnd}

2. **Run Development Server:**
   ${codeBlockStart}bash
   npm run dev
   # Press Ctrl+Shift+P to open performance dashboard
   ${codeBlockEnd}

3. **Run Performance Tests:**
   ${codeBlockStart}bash
   # Quick validation
   npm run test:perf:validation
   
   # Full baseline test
   npm run test:perf:baseline
   
   # Generate report
   npm run test:perf:report
   ${codeBlockEnd}

### For CI/CD

**Pull Request Workflow:**
- Baseline performance tests run automatically
- Performance regression detection compares against base branch
- Results commented on PR with detailed analysis
- Tests must pass for merge approval

**Production Deployment:**
- Full load testing suite runs on main branch
- Stress testing validates system capacity
- Performance monitoring alerts on degradation
- Daily health checks ensure ongoing performance

## ğŸ“ˆ Performance Trends

### Baseline Metrics (Target)
- **API Response Time:** < 500ms (95th percentile)
- **Alarm Trigger Latency:** < 150ms (95th percentile)
- **Frontend Load Time:** < 2.5s (LCP)
- **Error Rate:** < 1% (normal operations)
- **Bundle Size:** < 500KB (JavaScript)

### Performance Budget Compliance
${summary.k6_load_testing?.thresholds_passed ? 'âœ… k6 thresholds passing' : 'âŒ k6 thresholds failing'}
${summary.lighthouse_performance ? 'âœ… Lighthouse performance monitoring active' : 'âš ï¸ Lighthouse data not available'}

## ğŸ”§ Troubleshooting

### Common Issues

**k6 Tests Not Running:**
${codeBlockStart}bash
# Verify Docker is available
docker --version

# Test k6 Docker image
docker run --rm grafana/k6 version

# Run validation test
npm run test:perf:validation
${codeBlockEnd}

**React Profiler Not Showing:**
${codeBlockStart}bash
# Check environment variables
echo $REACT_APP_PERFORMANCE_PROFILING

# Verify development mode
echo $NODE_ENV

# Try keyboard shortcut: Ctrl+Shift+P
${codeBlockEnd}

**Lighthouse Tests Failing:**
${codeBlockStart}bash
# Verify server is running
curl http://localhost:4173

# Check Lighthouse CI config
npx lhci autorun --help
${codeBlockEnd}

## ğŸ“„ Reports and Artifacts

**Generated Files:**
- \`artifacts/perf-baseline-report.json\` - Machine-readable performance data
- \`artifacts/performance-test-report.md\` - Human-readable comprehensive report
- \`artifacts/lighthouse-ci-report.html\` - Frontend performance visualization
- \`performance/reports/\` - Detailed k6 test results (HTML format)
- \`.lighthouseci/\` - Lighthouse CI detailed reports and history

---
*Generated by Relife Performance Testing Infrastructure*
`;

  return markdown;
}

/**
 * Main execution
 */
async function main() {
  console.log('ğŸš€ Generating performance report...');

  // Load test results
  const k6Results = loadK6Results();
  const lighthouseResults = loadLighthouseResults();

  // Generate summary
  const summary = generatePerformanceSummary(k6Results, lighthouseResults);

  // Generate reports
  const markdownReport = generateMarkdownReport(summary);

  // Write artifacts
  const baselineReportPath = join(ARTIFACTS_DIR, 'perf-baseline-report.json');
  const markdownReportPath = join(ARTIFACTS_DIR, 'performance-test-report.md');

  writeFileSync(baselineReportPath, JSON.stringify(summary, null, 2));
  writeFileSync(markdownReportPath, markdownReport);

  console.log('ğŸ“Š Performance report generated:');
  console.log(`   - JSON: ${baselineReportPath}`);
  console.log(`   - Markdown: ${markdownReportPath}`);
  console.log(`   - Overall Status: ${summary.overall_status.toUpperCase()}`);

  // Exit with error code if tests failed
  if (summary.overall_status === 'fail') {
    process.exit(1);
  }
}

main().catch(error => {
  console.error('âŒ Error generating performance report:', error);
  process.exit(1);
});